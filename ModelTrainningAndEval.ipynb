{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ModelTrainningAndEval.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMQ/Ewf4OAdHNhKO6XHjjJz"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"HcKCQl37Qlg7"},"source":["!pip install -Iv keras=='2.3.1'\r\n","!pip install -Iv tensorflow=='2.1.0'\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a5hP9NojpeY0"},"source":["\r\n","import pandas as pd\r\n","import numpy as np\r\n","from sklearn.preprocessing import MinMaxScaler\r\n","from sklearn.model_selection import KFold\r\n","\r\n","from sklearn.ensemble import RandomForestRegressor\r\n","from sklearn.neighbors import KNeighborsRegressor\r\n","from sklearn.linear_model import LinearRegression\r\n","from sklearn.svm import SVR\r\n","\r\n","from keras.models import Sequential\r\n","from keras.layers import Dense\r\n","from keras.wrappers.scikit_learn import KerasRegressor\r\n","\r\n","from sklearn.model_selection import cross_validate\r\n","\r\n","import copy\r\n","\r\n","import matplotlib.pyplot as plt\r\n","import matplotlib as mpl\r\n","mpl.rcParams['figure.dpi'] = 300\r\n","import seaborn as sns\r\n","from matplotlib.patches import PathPatch\r\n","\r\n","from sklearn.metrics import mean_squared_error\r\n","from sklearn.metrics import r2_score\r\n","\r\n","import statistics\r\n","import os\r\n","from scipy.stats import shapiro\r\n","from scipy.stats import norm\r\n","import statistics\r\n","import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8RuTj230nwOl"},"source":["# Import the data\r\n","dataset = pd.read_excel('data.xlsx',sheet_name='data')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nh5H-GyWpj9L"},"source":["# Remove the outlier sample with the biggest porosity\r\n","\r\n","placesConsidered = [\"Pedreira_Sal\",\"Cachoeira_do_Roncador\"]\r\n","isOneOfThePlaces = lambda x: x in placesConsidered\r\n","vectorIsOneOfThePlaces = np.vectorize(isOneOfThePlaces)\r\n","filteredDataFrame = dataset[vectorIsOneOfThePlaces(dataset['place'])]\r\n","\r\n","# Removes the Tufa sample\r\n","filteredDataFrame = filteredDataFrame.loc[filteredDataFrame['Porosity (%)']!=filteredDataFrame['Porosity (%)'].max()]\r\n","filteredDataFrame = filteredDataFrame.reset_index()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-DWKafxcqIhf"},"source":["# Calculates the mean spectra\r\n","\r\n","workingDF = filteredDataFrame.groupby([\"sample\",\"place\"]).mean()\r\n","workingDF.reset_index(level=[\"sample\",\"place\"], inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"piTIjESLqTwD"},"source":["# Resample the dataset\r\n","\r\n","dfRoncador = workingDF[workingDF['place'] == 'Cachoeira_do_Roncador']\r\n","dfPedreiraSal = workingDF[workingDF['place'] == 'Pedreira_Sal']  \r\n","nSamplesPedreiraSal = min(int(len(dfRoncador) * 2.5 //10),\r\n","                                len(dfPedreiraSal))\r\n","dfPedreiraSal = dfPedreiraSal.sample(n=nSamplesPedreiraSal, replace=False, random_state=1)\r\n","\r\n","workingDF = pd.concat([dfPedreiraSal,dfRoncador]).reset_index()\r\n","workingDF = workingDF.drop(columns='index')    \r\n","    \r\n","XComplete = np.concatenate((workingDF.values[:,-1019:-1019].astype(np.float64),\r\n","                    workingDF.values[:,-969:-51].astype(np.float64)),\r\n","                    axis=1)\r\n","YComplete = workingDF['Porosity (%)'].values.astype(np.float64)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pgd6meOusptT"},"source":["# Dataset Normalization\r\n","\r\n","mmX = MinMaxScaler()\r\n","mmY = MinMaxScaler()\r\n","\r\n","XComplete = mmX.fit_transform(XComplete)\r\n","YComplete = mmY.fit_transform(YComplete.reshape(-1,1))\r\n","\r\n","finalDataFrame = pd.DataFrame(XComplete)#,columns = myColumns)\r\n","finalDataFrame['place'] = workingDF['place']\r\n","finalDataFrame['poro'] = workingDF['Porosity (%)']\r\n","\r\n","featureColumns = list(finalDataFrame.keys()[:-2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cItCZBrltwOH"},"source":["# Auxiliary Functions\r\n","upper_scores = None\r\n","def getKfoldIndexes():\r\n","  return copy.deepcopy(kfold_indexes)\r\n","\r\n","def evaluateModel(model, modelName, saveBandImportances = False):\r\n","    global upper_scores\r\n","    scores = cross_validate(model, \r\n","                            XComplete, \r\n","                            y = np.ravel(YComplete),\r\n","                            cv=getKfoldIndexes(), \r\n","                            scoring = {'mse': 'neg_mean_squared_error'},\r\n","                            return_estimator=True)\r\n","    upper_scores = scores\r\n","    #print('R2:',scores['test_r2'])\r\n","    print(modelName,'MSE',scores['test_mse'])\r\n","    generateGraphs(scores,modelName)\r\n","    if saveBandImportances:\r\n","        bandsImportance(scores['estimator'], modelName)\r\n","    \r\n","    return scores\r\n","\r\n","def bandsImportance(estimatorsList, modelName):\r\n","    colunasComImportancia = filteredDataFrame.columns[58:-51].values\r\n","    importanceList = []\r\n","    \r\n","    cross_val_indexes = getKfoldIndexes()\r\n","    \r\n","    acumImportance = np.array([0]*918)\r\n","    foldCountIndex = 0\r\n","    for est, foldsSeparation in list(zip(estimatorsList,\r\n","                                         cross_val_indexes)):\r\n","        foldTrain, foldTest = foldsSeparation\r\n","        yFold = YComplete[foldTrain]\r\n","        xFold = XComplete[foldTrain]\r\n","        foldCountIndex = foldCountIndex + 1\r\n","        \r\n","        result = permutation_importance(est, xFold, yFold, n_repeats=10,\r\n","                                        random_state=0)\r\n","        print('Processing Fold:', foldCountIndex)\r\n","        acumImportance = acumImportance + result.importances_mean  \r\n","    \r\n","    acumImportance = list(map(lambda x: x/10, acumImportance))\r\n","    colunaZip = list(zip(colunasComImportancia, acumImportance))\r\n","    colunaZip = sorted(colunaZip, reverse=True, key=lambda x:x[1])\r\n","    with open('BandImportances' + modelName+'.txt', 'w') as file_object:\r\n","        file_object.write(\"Band;Importance\\n\")\r\n","        for bandImportance, importanceValue in colunaZip:\r\n","            file_object.write(str(bandImportance) + \";\" + str(importanceValue) + \"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YYt3RXBftVEg"},"source":["# ML Preparation\r\n","listSamples = workingDF.groupby([\"sample\",\"place\"]).mean()#.values[:,3:-1].astype(np.float64)\r\n","listSamples.reset_index(level=[\"sample\",\"place\"], inplace=True)    \r\n","listSamples = list(listSamples['sample'].values)\r\n","\r\n","n_split = len(XComplete)\r\n","\r\n","    \r\n","\r\n","dictSampleIndexes = {}\r\n","for i in range(len(listSamples)):\r\n","    dictSampleIndexes[i] = list(workingDF[workingDF['sample'] == listSamples[i]].index)\r\n","    \r\n","kfold_indexes = list(KFold(n_split,shuffle=True).split(listSamples))\r\n","\r\n","newKfoldIndexes = []\r\n","\r\n","for train_fold, test_fold in kfold_indexes:\r\n","    listTrainFold = list(map(lambda x: dictSampleIndexes[x],train_fold))\r\n","    flatListTrain = [item for sublist in listTrainFold for item in sublist]\r\n","    \r\n","    listTestFold = list(map(lambda x: dictSampleIndexes[x],test_fold))\r\n","    flatListTest = [item for sublist in listTestFold for item in sublist]\r\n","    newKfoldIndexes.append((flatListTrain,flatListTest))\r\n","kfold_indexes = newKfoldIndexes\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oKkKE0eguSUL"},"source":["# Error estimation plots\r\n","\r\n","def generateGraphs(crosValidScores,modelName):\r\n","  resultList = crosValidScores['estimator']\r\n","  varia = 0\r\n","  cross_val_indexes = getKfoldIndexes()\r\n","  plt.style.use(['seaborn-ticks'])\r\n","  meanSquaredErrorsList = []\r\n","  listYhat = []\r\n","  listY = []\r\n","  for est in resultList:\r\n","    x_temp = cross_val_indexes[varia][1]\r\n","    if len(x_temp) > 0:\r\n","        ground_truth = YComplete[x_temp]\r\n","        x_temp = XComplete[x_temp]\r\n","        pred = est.predict(x_temp)\r\n","        listYhat = listYhat + list(pred)\r\n","        listY = listY + list(ground_truth.reshape(1,-1)[0])\r\n","        meanSquaredErrorsList.append(mean_squared_error(pred,\r\n","                                                        ground_truth.reshape(1,-1)[0]))\r\n","    else:\r\n","        print('Problem')\r\n","    varia = varia + 1\r\n","\r\n","  plt.plot(listY, listYhat,\"o\")\r\n","  plt.plot([0, 1], [0, 1], 'k-')\r\n","  linear = LinearRegression()\r\n","\r\n","  yArray = np.asarray(listY).reshape(len(listY),1)\r\n","  yHatArray = np.asarray(listYhat).reshape(len(listYhat),1)\r\n","  linear.fit(yArray,yHatArray)\r\n","  plt.plot(yArray, linear.predict(yArray),'k-', color='red')\r\n"," \r\n","    \r\n","  plt.xlabel('True Porosity')\r\n","  plt.ylabel(modelName+' Estimated Porosity')\r\n","\r\n","  r2Result = r2_score(listY,listYhat)\r\n","  print(\"R2:\", r2Result)\r\n","  print(\"MSE:\", meanSquaredErrorsList)\r\n","  \r\n","  trueMSE = statistics.mean(meanSquaredErrorsList)\r\n","  print('mean:', trueMSE)\r\n","  print('std:',statistics.stdev(meanSquaredErrorsList))\r\n","  plt.text(0, 0.92, 'R2: '+ str(round(r2Result,4)) + '\\nMSE: '+ str(round(trueMSE,6)), bbox=dict(facecolor='gray', alpha=0.5))\r\n","  plt.title(modelName)\r\n","  plt.grid(True)\r\n","\r\n","  plt.show()\r\n","  \r\n","\r\n","  errorsList = list(map(lambda x: x[0] - x[1], zip(listY,listYhat)))\r\n","  #extimateError(modelName, \r\n","  #              'residual error', \r\n","  #              errorsList,\r\n","  #              binsUse = [-.55,-.45,-.35,-.25,-.15,-.05,\r\n","  #                      .05,.15,.25,.35,.45,.55],\r\n","  #              normalFit=True)\r\n","  #\r\n","  #extimateError(modelName, 'MSE', meanSquaredErrorsList)\r\n","\r\n","def extimateError(modelName, \r\n","                  graphName, \r\n","                  errorsList, \r\n","                  binsUse = 10,\r\n","                  normalFit = False):\r\n","    \r\n","    \r\n","    # Fit a normal distribution to the data:\r\n","    \r\n","    plt.hist(errorsList, bins = binsUse, density=True)\r\n","    xmin, xmax = plt.xlim()\r\n","    ymin, ymax = plt.ylim()\r\n","    titleGraph = modelName + \" \" + graphName\r\n","    plt.title(titleGraph)\r\n","    if normalFit:\r\n","        \r\n","        shapTest = shapiro(errorsList)\r\n","        \r\n","        mu, std = norm.fit(errorsList)\r\n","        xGraph = np.linspace(xmin, xmax, 100)\r\n","        p = norm.pdf(xGraph, mu, std)\r\n","        plt.plot(xGraph, p, 'k', linewidth=2)\r\n","        textGraph = \"Fit results: \\nmu = %.2f \\nstd = %.2f \\nShapiro: %.4f \\npval: %s\" % (mu, std, shapTest[0], ('%.2E' if shapTest[1] < 0.0001 else '%.6f') % shapTest[1])\r\n","        plt.text(xmin,\r\n","                 ymax * 0.95, \r\n","                 textGraph, \r\n","                 bbox=dict(facecolor='gray', alpha=0.5),\r\n","                 horizontalalignment='left',\r\n","                 verticalalignment='top')\r\n","        print('Normal Fit\\nShapiro:',\r\n","              shapTest[0],\r\n","              'pval:',\r\n","              shapTest[1])\r\n","    plt.grid()\r\n","    plt.show()\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K9StlWaKuzDx"},"source":["# Linear Regression\r\n","linear = LinearRegression()\r\n","evaluateModel(linear,'Linear Reg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ip33-sTqu5gU"},"source":["# SVR Model Evaluation\r\n","svr = SVR(gamma='scale', C=1.0, epsilon=0.05)\r\n","evaluateModel(svr, 'SVR', saveBandImportances=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zfn6Bwyju-xs"},"source":["# KNN Model Evaluation\r\n","knn = KNeighborsRegressor(n_neighbors=3)\r\n","evaluateModel(knn,'KNN', saveBandImportances=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7lyWKPw4vD3z"},"source":["# Random Forest\r\n","forest = RandomForestRegressor(n_estimators=10)\r\n","evaluateModel(forest, 'RF', saveBandImportances=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jtDNf1_SvOAX"},"source":["# ANN Model Evaluation\r\n","\r\n","def buildANN():\r\n","  c = Sequential()               \r\n","  c.add(Dense(units = 8,\r\n","              kernel_initializer = 'uniform',\r\n","              activation = 'sigmoid', \r\n","              input_dim = len(XComplete[0,:])))\r\n","  c.add(Dense(units = 8, \r\n","              kernel_initializer = 'uniform',\r\n","              activation = 'sigmoid'))\r\n","  c.add(Dense(units = 1, kernel_initializer = 'uniform',\r\n","              activation = 'sigmoid'))\r\n","  c.compile(optimizer = 'adam',\r\n","          loss = 'mean_squared_error', \r\n","          metrics=['mse'])\r\n","  return c\r\n","\r\n","ann = keras.wrappers.scikit_learn.KerasRegressor(buildANN, \r\n","                                                 epochs=1600, \r\n","                                                 batch_size = 1, \r\n","                                                 verbose=2)\r\n","evaluateModel(ann, 'ANN', saveBandImportances=False)"],"execution_count":null,"outputs":[]}]}